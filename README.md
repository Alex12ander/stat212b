# stat212b
Topics Course on Deep Learning for Spring 2016

UC Berkeley, Statistics Department

##Syllabus

### 1st part: Convolutional Neural Networks
  - Invariance, stability.
  - Variability models (deformation model, stochastic model). 
  - Scattering
  - Extensions ( recent arvix paper ) 
  - Group Formalism 
  - Supervised Learning: classification. 
  - Properties of CNN representations: invertibility? stability? invariance. 
  - covariance/invariance: capsules and related models
  - Connections with other models: dictionary learning, LISTA, Random Forests
  - Other tasks: localization, regression. 
  - Embeddings (DrLim), inverse problems 
  - Extensions to non-euclidean domains?
  - Dynamical systems: RNNs and optimal control. 
  - Guest Lecture??
  
### 2nd part: Deep Unsupervised Learning
 - Autoencoders (standard, denoising, contractive, etc etc)
 - Variational Autoencoders
 - Adversarial Generative Networks
 - Maximum Entropy Distributions
 - Open Problems
   

### 3rd part: Miscellaneous Topics
- Non-convex optimization theory for deep networks (Rene, Yann, Ganguli)
- Stochastic Optimization
- Attention and Memory Models ( Cho, Weston, NTM, applications ) 
  


## Schedule

Lec1 Intro and Logistics

Lec2 Representations for Recognition : stability, variability. 
 Kernel approaches / Feature extraction. Properties. 
 
Lec3 Convnets / Scattering

Lec4 Scattering Properties

Lec5 Further Scattering 

Lec6 Supervised Learning: classfication. Properties of learnt representations

Lec7 Properties of learnt representations. Covariance and Invariance.
     Estimation properties: above generalization error. Redundancy in parameter space.

Lec8 Connections with other models (DL, Lista, Random Forests, CART)

Lec9 Representations of stationary processes. Properties. 

Lec10 Other high level tasks: localization, regression, embedding, inverse problems. 

Lec11 Extensions to non-Euclidean domain. Sequential Data RNNs. 

Lec12 Guest Lecture ( W. Zaremba ) 

Lec13 Unsupervised Learning: autoencoders. Density estimation. Parzen estimators. Curse of dimensionality

Lec14 Variational Autoencoders

Lec15 Adversarial Generative Networks

Lec16 Maximum Entropy Distributions

Lec17 Self-supervised models (analogies, video prediction, text, word2vec). 

Lec18 Guest Lecture ( I. Goodfellow ) 

Lec19 Non-convex Optimization: parameter redundancy, spin-glass, optimiality certificates. stability

Lec20 Stochastic Optimization

Lec21 Reasoning, Attention and Memory: New trends of the field and challenges. 
      limits of sequential representations (need for attention and memory). 
      modern enhancements (NTM, Memnets, Stack/RNNs, etc.)

Lec22 Applications and Open Problems


